{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import PATH, LIBRISPEECH_SAMPLING_RATE\n",
    "from data import LibriSpeechDataset, label_to_sex\n",
    "from models import DilatedNet, ConvNet\n",
    "from utils import whiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = PATH + '/models/max_pooling__n_layers=7__n_filters=64__downsampling=1__n_seconds=3.torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters determined from filename:\n",
      "{\n",
      "    \"n_layers\": 7, \n",
      "    \"n_filters\": 64, \n",
      "    \"n_seconds\": 3, \n",
      "    \"downsampling\": 1\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (initialconv): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (initialbn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn_0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn_3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn_4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn_5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn_6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (finalconv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = model_path.split('/')[-1].split('__')[0]\n",
    "model_name = model_path.split('/')[-1].split('.')[0]\n",
    "model_params = {i.split('=')[0]: int(i.split('=')[1]) for i in model_name.split('__')[1:]}\n",
    "\n",
    "# Here we assume that the model was trained on the LibriSpeech dataset\n",
    "model_sampling_rate = LIBRISPEECH_SAMPLING_RATE/model_params['downsampling']\n",
    "model_num_samples = model_params['n_seconds']*model_sampling_rate\n",
    "\n",
    "print('Model parameters determined from filename:')\n",
    "print(json.dumps(model_params, indent=4))\n",
    "\n",
    "if model_type == 'max_pooling':\n",
    "    model = ConvNet(model_params['n_filters'], model_params['n_layers'])\n",
    "elif model_type == 'dilated':\n",
    "    model = DilatedNet(model_params['n_filters'], model_params['n_depth'], model_params['n_stacks'])\n",
    "else:\n",
    "    raise(ValueError, 'Model type not recognised.')\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.double()\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 86/2703 [00:00<00:03, 857.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising LibriSpeechDataset with length = 48000 and subsets = dev-clean\n",
      "Indexing dev-clean...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2703/2703 [00:04<00:00, 648.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished indexing data. 2303 usable files found.\n"
     ]
    }
   ],
   "source": [
    "testset = LibriSpeechDataset('dev-clean',LIBRISPEECH_SAMPLING_RATE*model_params['n_seconds'],stochastic=False,cache=False)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=16,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6155831554f048a9a70b967b8d3b3e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2303), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "for i in tqdm(range(len(testset))):\n",
    "    instance, label = testset[i]\n",
    "    instance = whiten(torch.from_numpy(instance[np.newaxis,:]))\n",
    "        \n",
    "     # New resampling\n",
    "    instance_cuda = torch.from_numpy(\n",
    "        resample(\n",
    "            instance,\n",
    "            int(LIBRISPEECH_SAMPLING_RATE*model_params['n_seconds']/model_params['downsampling']),\n",
    "            axis=1\n",
    "        )\n",
    "    ).reshape((1,1,int(LIBRISPEECH_SAMPLING_RATE*model_params['n_seconds']/model_params['downsampling'])))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(instance_cuda)[0][0].cpu().numpy()\n",
    "        \n",
    "    df.append({\n",
    "        'i': i,\n",
    "        'name': testset.datasetid_to_name[i],\n",
    "        'sex': label_to_sex[label],\n",
    "        'rms': np.sqrt(np.square(instance)).mean(),\n",
    "        'rmedians': np.median(np.sqrt(np.square(instance))),\n",
    "        'mean': instance.mean(),\n",
    "        'pred':pred,\n",
    "        'label': label\n",
    "    })\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    error=abs(df['pred'].astype(float)-df['label'].astype(int)),\n",
    "    label=df['label'].astype(int),\n",
    "    correct=(df['pred'] > 0.5) == df['label'],\n",
    "    pred=df['pred'].astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred.mean</th>\n",
       "      <th>label.mean</th>\n",
       "      <th>error.mean</th>\n",
       "      <th>error.max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kathy Caver</th>\n",
       "      <td>0.686460</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313540</td>\n",
       "      <td>0.941445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dexter</th>\n",
       "      <td>0.234752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234752</td>\n",
       "      <td>0.780647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>President Lethe</th>\n",
       "      <td>0.144391</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144391</td>\n",
       "      <td>0.948249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jennifer Wiginton</th>\n",
       "      <td>0.888373</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111627</td>\n",
       "      <td>0.381209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicodemus</th>\n",
       "      <td>0.108616</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108616</td>\n",
       "      <td>0.703835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stephen Kinford</th>\n",
       "      <td>0.106456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106456</td>\n",
       "      <td>0.882708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peter Eastman</th>\n",
       "      <td>0.079562</td>\n",
       "      <td>0</td>\n",
       "      <td>0.079562</td>\n",
       "      <td>0.785736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark Nelson</th>\n",
       "      <td>0.056028</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056028</td>\n",
       "      <td>0.967619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOICEGUY</th>\n",
       "      <td>0.036067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036067</td>\n",
       "      <td>0.500753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>badey</th>\n",
       "      <td>0.035517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035517</td>\n",
       "      <td>0.218884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JenniferRutters</th>\n",
       "      <td>0.973986</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>0.199550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John Rose</th>\n",
       "      <td>0.024201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024201</td>\n",
       "      <td>0.267795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scott Walter</th>\n",
       "      <td>0.022922</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022922</td>\n",
       "      <td>0.339498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ransom</th>\n",
       "      <td>0.980291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019709</td>\n",
       "      <td>0.252933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thestorygirl</th>\n",
       "      <td>0.986980</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013020</td>\n",
       "      <td>0.492925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jill Engle</th>\n",
       "      <td>0.989293</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.075777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tonia</th>\n",
       "      <td>0.989301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.045885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jean Bascom</th>\n",
       "      <td>0.989382</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.094341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mary J</th>\n",
       "      <td>0.990884</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009116</td>\n",
       "      <td>0.126875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M. Bertke</th>\n",
       "      <td>0.992786</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>0.057983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aquielisunari</th>\n",
       "      <td>0.006904</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>0.086762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winston Tharp</th>\n",
       "      <td>0.005807</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.131007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark Welch</th>\n",
       "      <td>0.005540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.107990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Christie Nowak</th>\n",
       "      <td>0.994567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.038310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharon Bautista</th>\n",
       "      <td>0.994595</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.030077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brian von Dedenroth</th>\n",
       "      <td>0.005214</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.052169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arielle Lipshaw</th>\n",
       "      <td>0.995071</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.040827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wendy Belcher</th>\n",
       "      <td>0.995967</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.052988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E. Tavano</th>\n",
       "      <td>0.996222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.014253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zinniz</th>\n",
       "      <td>0.996779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.033391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David Mix</th>\n",
       "      <td>0.002990</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.023803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calystra</th>\n",
       "      <td>0.997088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.021731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JudyGibson</th>\n",
       "      <td>0.997306</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.026968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iamartin</th>\n",
       "      <td>0.997550</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.014937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Renata</th>\n",
       "      <td>0.997718</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.050438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S R Colon</th>\n",
       "      <td>0.998058</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.029020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David Mecionis</th>\n",
       "      <td>0.001918</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.016755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nprigoda</th>\n",
       "      <td>0.998877</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.007336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fling93</th>\n",
       "      <td>0.000848</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.009078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael Packard</th>\n",
       "      <td>0.000840</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.007735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pred.mean  label.mean  error.mean  error.max\n",
       "name                                                             \n",
       "Kathy Caver           0.686460           1    0.313540   0.941445\n",
       "dexter                0.234752           0    0.234752   0.780647\n",
       "President Lethe       0.144391           0    0.144391   0.948249\n",
       "Jennifer Wiginton     0.888373           1    0.111627   0.381209\n",
       "Nicodemus             0.108616           0    0.108616   0.703835\n",
       "Stephen Kinford       0.106456           0    0.106456   0.882708\n",
       "Peter Eastman         0.079562           0    0.079562   0.785736\n",
       "Mark Nelson           0.056028           0    0.056028   0.967619\n",
       "VOICEGUY              0.036067           0    0.036067   0.500753\n",
       "badey                 0.035517           0    0.035517   0.218884\n",
       "JenniferRutters       0.973986           1    0.026014   0.199550\n",
       "John Rose             0.024201           0    0.024201   0.267795\n",
       "Scott Walter          0.022922           0    0.022922   0.339498\n",
       "Ransom                0.980291           1    0.019709   0.252933\n",
       "thestorygirl          0.986980           1    0.013020   0.492925\n",
       "Jill Engle            0.989293           1    0.010707   0.075777\n",
       "Tonia                 0.989301           1    0.010699   0.045885\n",
       "Jean Bascom           0.989382           1    0.010618   0.094341\n",
       "Mary J                0.990884           1    0.009116   0.126875\n",
       "M. Bertke             0.992786           1    0.007214   0.057983\n",
       "aquielisunari         0.006904           0    0.006904   0.086762\n",
       "Winston Tharp         0.005807           0    0.005807   0.131007\n",
       "Mark Welch            0.005540           0    0.005540   0.107990\n",
       "Christie Nowak        0.994567           1    0.005433   0.038310\n",
       "Sharon Bautista       0.994595           1    0.005405   0.030077\n",
       "Brian von Dedenroth   0.005214           0    0.005214   0.052169\n",
       "Arielle Lipshaw       0.995071           1    0.004929   0.040827\n",
       "Wendy Belcher         0.995967           1    0.004033   0.052988\n",
       "E. Tavano             0.996222           1    0.003778   0.014253\n",
       "zinniz                0.996779           1    0.003221   0.033391\n",
       "David Mix             0.002990           0    0.002990   0.023803\n",
       "calystra              0.997088           1    0.002912   0.021731\n",
       "JudyGibson            0.997306           1    0.002694   0.026968\n",
       "iamartin              0.997550           1    0.002450   0.014937\n",
       "Renata                0.997718           1    0.002282   0.050438\n",
       "S R Colon             0.998058           1    0.001942   0.029020\n",
       "David Mecionis        0.001918           0    0.001918   0.016755\n",
       "nprigoda              0.998877           1    0.001123   0.007336\n",
       "fling93               0.000848           0    0.000848   0.009078\n",
       "Michael Packard       0.000840           0    0.000840   0.007735"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = df.groupby('name').agg({'error': ['mean','max'], 'pred': 'mean', 'label': 'mean'})\n",
    "gb.columns = ['.'.join(col).strip() for col in gb.columns.values]\n",
    "gb.sort_values('error.mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 out of 40 (80.0%) of speakers in the validation set are never misclassified.\n"
     ]
    }
   ],
   "source": [
    "print '{} out of {} ({}%) of speakers in the validation set are never misclassified.'.format(\n",
    "    len(gb[gb['error.max']<0.5]),\n",
    "    len(gb),\n",
    "    len(gb[gb['error.max']<0.5])*100./len(gb)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
