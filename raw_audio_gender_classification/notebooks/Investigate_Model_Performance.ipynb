{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from raw_audio_gender_classification.config import PATH, LIBRISPEECH_SAMPLING_RATE\n",
    "from raw_audio_gender_classification.data import LibriSpeechDataset, label_to_sex\n",
    "from raw_audio_gender_classification.models import DilatedNet, ConvNet\n",
    "from raw_audio_gender_classification.utils import whiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TqdmDeprecationWarning**:This function will be removed in tqdm==5.0.0\n",
    "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_path = PATH + '/models/max_pooling__n_layers=7__n_filters=64__downsampling=1__n_seconds=3.torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model parameters determined from filename:\n",
      "{\n",
      "    \"n_layers\": 7,\n",
      "    \"n_filters\": 64,\n",
      "    \"downsampling\": 1,\n",
      "    \"n_seconds\": 3\n",
      "}\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "ConvNet(\n  (initialconv): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (initialbn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (bn_0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (bn_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (bn_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (bn_3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (bn_4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (bn_5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (bn_6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (finalconv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (output): Linear(in_features=64, out_features=1, bias=True)\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "model_type = model_path.split('/')[-1].split('__')[0]\n",
    "model_name = model_path.split('/')[-1].split('.')[0]\n",
    "model_params = {i.split('=')[0]: int(i.split('=')[1]) for i in model_name.split('__')[1:]}\n",
    "\n",
    "# Here we assume that the model was trained on the LibriSpeech dataset\n",
    "model_sampling_rate = LIBRISPEECH_SAMPLING_RATE/model_params['downsampling']\n",
    "model_num_samples = model_params['n_seconds']*model_sampling_rate\n",
    "\n",
    "print('Model parameters determined from filename:')\n",
    "print(json.dumps(model_params, indent=4))\n",
    "\n",
    "if model_type == 'max_pooling':\n",
    "    model = ConvNet(model_params['n_filters'], model_params['n_layers'])\n",
    "elif model_type == 'dilated':\n",
    "    model = DilatedNet(model_params['n_filters'], model_params['n_depth'], model_params['n_stacks'])\n",
    "else:\n",
    "    raise(ValueError, 'Model type not recognised.')\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.double()\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Initialising LibriSpeechDataset with length = 48000 and subsets = dev-clean\n",
      "Indexing dev-clean...\n",
      "Finished indexing data. 2303 usable files found.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "b'Skipping line 45: expected 5 fields, saw 7\\n'\n",
      "100%|██████████| 2703/2703 [00:06<00:00, 410.64it/s]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "testset = LibriSpeechDataset('dev-clean',LIBRISPEECH_SAMPLING_RATE*model_params['n_seconds'],stochastic=False,cache=False)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=16,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\Arnau\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n",
      "C:\\Users\\Arnau\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2303.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "494fd0ff765b4a13a34eccc11901e29b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df = []\n",
    "for i in tqdm(range(len(testset))):\n",
    "    instance, label = testset[i]\n",
    "    instance = whiten(torch.from_numpy(instance[np.newaxis,:]))\n",
    "        \n",
    "     # New resampling\n",
    "    instance_cuda = torch.from_numpy(\n",
    "        resample(\n",
    "            instance,\n",
    "            int(LIBRISPEECH_SAMPLING_RATE*model_params['n_seconds']/model_params['downsampling']),\n",
    "            axis=1\n",
    "        )\n",
    "    ).reshape((1,1,int(LIBRISPEECH_SAMPLING_RATE*model_params['n_seconds']/model_params['downsampling'])))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(instance_cuda)[0][0].cpu().numpy()\n",
    "        \n",
    "    df.append({\n",
    "        'i': i,\n",
    "        'name': testset.datasetid_to_name[i],\n",
    "        'sex': label_to_sex[label],\n",
    "        'rms': np.sqrt(np.square(instance)).mean(),\n",
    "        'rmedians': np.median(np.sqrt(np.square(instance))),\n",
    "        'mean': instance.mean(),\n",
    "        'pred':pred,\n",
    "        'label': label\n",
    "    })\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    error=abs(df['pred'].astype(float)-df['label'].astype(int)),\n",
    "    label=df['label'].astype(int),\n",
    "    correct=(df['pred'] > 0.5) == df['label'],\n",
    "    pred=df['pred'].astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     error.mean  error.max  pred.mean  label.mean\nname                                                             \nJenniferRutters        0.973986   0.999665   0.973986           0\nKathy Caver            0.686460   0.991581   0.686460           0\ndexter                 0.234752   0.780647   0.234752           0\nPresident Lethe        0.144391   0.948249   0.144391           0\nJennifer Wiginton      0.111627   0.381209   0.888373           1\nNicodemus              0.108616   0.703835   0.108616           0\nStephen Kinford        0.106456   0.882708   0.106456           0\nPeter Eastman          0.079562   0.785736   0.079562           0\nMark Nelson            0.056028   0.967619   0.056028           0\nVOICEGUY               0.036067   0.500753   0.036067           0\nbadey                  0.035517   0.218884   0.035517           0\nJohn Rose              0.024201   0.267795   0.024201           0\nScott Walter           0.022922   0.339498   0.022922           0\nRansom                 0.019709   0.252933   0.980291           1\nthestorygirl           0.013020   0.492925   0.986980           1\nJill Engle             0.010707   0.075777   0.989293           1\nTonia                  0.010699   0.045885   0.989301           1\nJean Bascom            0.010618   0.094341   0.989382           1\nMary J                 0.009116   0.126875   0.990884           1\nM. Bertke              0.007214   0.057983   0.992786           1\naquielisunari          0.006904   0.086762   0.006904           0\nWinston Tharp          0.005807   0.131007   0.005807           0\nMark Welch             0.005540   0.107990   0.005540           0\nChristie Nowak         0.005433   0.038310   0.994567           1\nSharon Bautista        0.005405   0.030077   0.994595           1\nBrian von Dedenroth    0.005214   0.052169   0.005214           0\nArielle Lipshaw        0.004929   0.040827   0.995071           1\nWendy Belcher          0.004033   0.052988   0.995967           1\nE. Tavano              0.003778   0.014253   0.996222           1\nzinniz                 0.003221   0.033391   0.996779           1\nDavid Mix              0.002990   0.023803   0.002990           0\ncalystra               0.002912   0.021731   0.997088           1\nJudyGibson             0.002694   0.026968   0.997306           1\niamartin               0.002450   0.014937   0.997550           1\nRenata                 0.002282   0.050438   0.997718           1\nS R Colon              0.001942   0.029020   0.998058           1\nDavid Mecionis         0.001918   0.016755   0.001918           0\nnprigoda               0.001123   0.007336   0.998877           1\nfling93                0.000848   0.009078   0.000848           0\nMichael Packard        0.000840   0.007735   0.000840           0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>error.mean</th>\n      <th>error.max</th>\n      <th>pred.mean</th>\n      <th>label.mean</th>\n    </tr>\n    <tr>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>JenniferRutters</th>\n      <td>0.973986</td>\n      <td>0.999665</td>\n      <td>0.973986</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Kathy Caver</th>\n      <td>0.686460</td>\n      <td>0.991581</td>\n      <td>0.686460</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>dexter</th>\n      <td>0.234752</td>\n      <td>0.780647</td>\n      <td>0.234752</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>President Lethe</th>\n      <td>0.144391</td>\n      <td>0.948249</td>\n      <td>0.144391</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Jennifer Wiginton</th>\n      <td>0.111627</td>\n      <td>0.381209</td>\n      <td>0.888373</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Nicodemus</th>\n      <td>0.108616</td>\n      <td>0.703835</td>\n      <td>0.108616</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Stephen Kinford</th>\n      <td>0.106456</td>\n      <td>0.882708</td>\n      <td>0.106456</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Peter Eastman</th>\n      <td>0.079562</td>\n      <td>0.785736</td>\n      <td>0.079562</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Mark Nelson</th>\n      <td>0.056028</td>\n      <td>0.967619</td>\n      <td>0.056028</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>VOICEGUY</th>\n      <td>0.036067</td>\n      <td>0.500753</td>\n      <td>0.036067</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>badey</th>\n      <td>0.035517</td>\n      <td>0.218884</td>\n      <td>0.035517</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>John Rose</th>\n      <td>0.024201</td>\n      <td>0.267795</td>\n      <td>0.024201</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Scott Walter</th>\n      <td>0.022922</td>\n      <td>0.339498</td>\n      <td>0.022922</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Ransom</th>\n      <td>0.019709</td>\n      <td>0.252933</td>\n      <td>0.980291</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>thestorygirl</th>\n      <td>0.013020</td>\n      <td>0.492925</td>\n      <td>0.986980</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Jill Engle</th>\n      <td>0.010707</td>\n      <td>0.075777</td>\n      <td>0.989293</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Tonia</th>\n      <td>0.010699</td>\n      <td>0.045885</td>\n      <td>0.989301</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Jean Bascom</th>\n      <td>0.010618</td>\n      <td>0.094341</td>\n      <td>0.989382</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Mary J</th>\n      <td>0.009116</td>\n      <td>0.126875</td>\n      <td>0.990884</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>M. Bertke</th>\n      <td>0.007214</td>\n      <td>0.057983</td>\n      <td>0.992786</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>aquielisunari</th>\n      <td>0.006904</td>\n      <td>0.086762</td>\n      <td>0.006904</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Winston Tharp</th>\n      <td>0.005807</td>\n      <td>0.131007</td>\n      <td>0.005807</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Mark Welch</th>\n      <td>0.005540</td>\n      <td>0.107990</td>\n      <td>0.005540</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Christie Nowak</th>\n      <td>0.005433</td>\n      <td>0.038310</td>\n      <td>0.994567</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Sharon Bautista</th>\n      <td>0.005405</td>\n      <td>0.030077</td>\n      <td>0.994595</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Brian von Dedenroth</th>\n      <td>0.005214</td>\n      <td>0.052169</td>\n      <td>0.005214</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Arielle Lipshaw</th>\n      <td>0.004929</td>\n      <td>0.040827</td>\n      <td>0.995071</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Wendy Belcher</th>\n      <td>0.004033</td>\n      <td>0.052988</td>\n      <td>0.995967</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>E. Tavano</th>\n      <td>0.003778</td>\n      <td>0.014253</td>\n      <td>0.996222</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>zinniz</th>\n      <td>0.003221</td>\n      <td>0.033391</td>\n      <td>0.996779</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>David Mix</th>\n      <td>0.002990</td>\n      <td>0.023803</td>\n      <td>0.002990</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>calystra</th>\n      <td>0.002912</td>\n      <td>0.021731</td>\n      <td>0.997088</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>JudyGibson</th>\n      <td>0.002694</td>\n      <td>0.026968</td>\n      <td>0.997306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>iamartin</th>\n      <td>0.002450</td>\n      <td>0.014937</td>\n      <td>0.997550</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Renata</th>\n      <td>0.002282</td>\n      <td>0.050438</td>\n      <td>0.997718</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>S R Colon</th>\n      <td>0.001942</td>\n      <td>0.029020</td>\n      <td>0.998058</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>David Mecionis</th>\n      <td>0.001918</td>\n      <td>0.016755</td>\n      <td>0.001918</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>nprigoda</th>\n      <td>0.001123</td>\n      <td>0.007336</td>\n      <td>0.998877</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>fling93</th>\n      <td>0.000848</td>\n      <td>0.009078</td>\n      <td>0.000848</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Michael Packard</th>\n      <td>0.000840</td>\n      <td>0.007735</td>\n      <td>0.000840</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "gb = df.groupby('name').agg({'error': ['mean','max'], 'pred': 'mean', 'label': 'mean'})\n",
    "gb.columns = ['.'.join(col).strip() for col in gb.columns.values]\n",
    "gb.sort_values('error.mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "31 out of 40 (77.5%) of speakers in the validation set are never misclassified.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('{} out of {} ({}%) of speakers in the validation set are never misclassified.'.format(\n",
    "    len(gb[gb['error.max']<0.5]),\n",
    "    len(gb),\n",
    "    len(gb[gb['error.max']<0.5])*100./len(gb)\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}